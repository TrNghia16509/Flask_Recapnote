from flask import Flask, request, jsonify
import os, tempfile, json, docx, requests, urllib.parse
from dotenv import load_dotenv
from flask_cors import CORS
import pdfplumber
from b2sdk.v2 import InMemoryAccountInfo, B2Api
from groq import Groq
import time 
from pydub import AudioSegment
import torch
import os
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

device = "cuda" if torch.cuda.is_available() else "cpu"
model_id = "vinai/PhoWhisper-medium"   # c√≥ th·ªÉ thay b·∫±ng PhoWhisper-small/large

model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id).to(device)
processor = AutoProcessor.from_pretrained(model_id)

asr_pipeline = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    device=0 if device == "cuda" else -1,
)

# ============= Config ============
app = Flask(__name__)
CORS(app)
load_dotenv()

# Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng b·∫Øt bu·ªôc
required_env = ["ASSEMBLYAI_API_KEY", "B2_APPLICATION_KEY_ID", "B2_APPLICATION_KEY", "B2_BUCKET_NAME"]
for env_var in required_env:
    if not os.getenv(env_var):
        raise RuntimeError(f"‚ùå Missing environment variable: {env_var}")

# API keys
GROQ_API_KEYS = [k.strip() for k in os.getenv("GROQ_API_KEYS", "").split(",") if k.strip()]
if not GROQ_API_KEYS:
    raise RuntimeError("‚ùå B·ªã l·ªói)

# Backblaze B2 (Private Bucket)
info = InMemoryAccountInfo()
b2_api = B2Api(info)
b2_api.authorize_account("production", os.getenv("B2_APPLICATION_KEY_ID"), os.getenv("B2_APPLICATION_KEY"))
bucket = b2_api.get_bucket_by_name(os.getenv("B2_BUCKET_NAME"))

# === Helpers ===
def extract_text_from_pdf(file_path):
    with pdfplumber.open(file_path) as pdf:
        return "\n".join([p.extract_text() for p in pdf.pages if p.extract_text()])

def extract_text_from_docx(file_path):
    doc = docx.Document(file_path)
    return "\n".join([p.text for p in doc.paragraphs])

def upload_to_b2(local_path, b2_filename, content_type):
    with open(local_path, "rb") as f:
        bucket.upload_bytes(f.read(), b2_filename, content_type=content_type)
    return b2_filename

def get_signed_url(file_name, valid_seconds=3600):
    """T·∫°o signed URL t·∫°m th·ªùi cho file private"""
    auth_token = bucket.get_download_authorization(
        file_name_prefix=file_name,
        valid_duration_in_seconds=valid_seconds
    )
    base_url = b2_api.account_info.get_download_url()
    download_url = f"{base_url}/file/{bucket.name}/{urllib.parse.quote(file_name)}"
    return f"{download_url}?Authorization={auth_token}"

def transcribe_with_phowhisper(audio_path: str) -> str:
    """Nh·∫≠n file audio v√† tr·∫£ v·ªÅ transcript ti·∫øng Vi·ªát"""
    result = asr_pipeline(audio_path, generate_kwargs={"language": "auto"})
    return result["text"]


    # 1. Chuy·ªÉn file audio sang WAV 16-bit PCM n·∫øu ƒë·ªãnh d·∫°ng kh√¥ng chu·∫©n
    ext = os.path.splitext(file_path)[1].lower()
    if ext not in [".wav", ".mp3", ".m4a", ".flac"]:
        print(f"üîÑ Chuy·ªÉn ƒë·ªïi {ext} ‚Üí .wav")
        audio = AudioSegment.from_file(file_path)
        wav_path = file_path + ".wav"
        audio.export(wav_path, format="wav")
        file_path = wav_path

    # 2. Upload theo t·ª´ng chunk 5MB
    def read_file_in_chunks(path, chunk_size=6_291_456):
        with open(path, "rb") as f:
            while True:
                data = f.read(chunk_size)
                if not data:
                    break
                yield data

def groq_generate(prompt, max_tokens=1000, retries=3):
    """G·ªçi Groq API l·∫ßn l∆∞·ª£t t·ª´ng key khi b·ªã rate limit"""
    url = "https://api.groq.com/openai/v1/chat/completions"
    payload = {
        "model": "llama3-70b-8192",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": max_tokens,
        "temperature": 0.7
    }

    # Th·ª≠ t·ª´ng key
    for key_index, api_key in enumerate(GROQ_API_KEYS):
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        for attempt in range(retries):
            res = requests.post(url, headers=headers, json=payload)
            if res.status_code == 429:
                wait_time = 2 ** attempt
                print(f"‚ö†Ô∏è Th·ª≠ l·∫°i sau {wait_time}s...")
                time.sleep(wait_time)
                continue
            elif res.status_code >= 500:
                break
            try:
                res.raise_for_status()
                return res.json()["choices"][0]["message"]["content"].strip()
            except Exception as e:
                print(f"‚ö†Ô∏è Key #{key_index+1} l·ªói: {e}")
                break  # sang key ti·∫øp theo

    raise Exception("‚ùå B·ªã l·ªói")
    
def split_text(text, chunk_size=3000):
    """Chia vƒÉn b·∫£n th√†nh c√°c ƒëo·∫°n nh·ªè"""
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]
    
# === Routes ===
@app.route("/", methods=["GET"])
def home():
    return {"status": "‚úÖ Flask backend is running"}, 200

@app.route("/process_file", methods=["POST"])
def process_file():
    try:
        if "file" not in request.files:
            return jsonify({"error": "Thi·∫øu file"}), 400

        file = request.files["file"]
        language_code = request.form.get("language_code")
        language_name = request.form.get("language_name")

        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            file.save(tmp.name)
            ext = file.filename.lower()

            if ext.endswith((".mp3", ".wav")):
                text = transcribe_with_phowhisper(tmp.name, language_code)
                content_type = "audio/wav"
            elif ext.endswith(".pdf"):
                text = extract_text_from_pdf(tmp.name)
                content_type = "application/pdf"
            elif ext.endswith(".docx"):
                text = extract_text_from_docx(tmp.name)
                content_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            else:
                os.remove(tmp.name)
                return jsonify({"error": "ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£"}), 400

        # === X·ª≠ l√Ω Groq ===
        # Ch·ªß ƒë·ªÅ
        subject = groq_generate(f"H√£y cho bi·∫øt ch·ªß ƒë·ªÅ ch√≠nh c·ªßa n·ªôi dung sau b·∫±ng {language_code}: {text[:4000]}")

        # T√≥m t·∫Øt theo t·ª´ng ph·∫ßn
        chunks = split_text(text, chunk_size=3000)
        partial_summaries = []
        for idx, chunk in enumerate(chunks):
            print(f"üîπ T√≥m t·∫Øt ƒëo·∫°n {idx+1}/{len(chunks)}")
            summary_part = groq_generate(
                f"T√≥m t·∫Øt ƒëo·∫°n vƒÉn sau b·∫±ng {language_name}, ng·∫Øn g·ªçn, ƒë·∫ßy ƒë·ªß √Ω:\n\n{chunk}",
                max_tokens=800
            )
            partial_summaries.append(summary_part)
            time.sleep(1)  # Gi·∫£m t·∫£i API

        # T√≥m t·∫Øt cu·ªëi c√πng t·ª´ c√°c b·∫£n t√≥m t·∫Øt nh·ªè
        final_summary = groq_generate(
            f"D∆∞·ªõi ƒë√¢y l√† c√°c b·∫£n t√≥m t·∫Øt t·ª´ng ph·∫ßn. H√£y g·ªôp ch√∫ng th√†nh m·ªôt b·∫£n t√≥m t·∫Øt ho√†n ch·ªânh, m·∫°ch l·∫°c, b·∫±ng {language_name}:\n\n"
            + "\n\n".join(partial_summaries),
            max_tokens=1000
        )

        # Upload file g·ªëc
        safe_file_name = f"uploads/{file.filename}"
        upload_to_b2(tmp.name, safe_file_name, content_type)
        file_url = get_signed_url(safe_file_name)

        # Upload JSON k·∫øt qu·∫£
        result_data = {
            "subject": subject,
            "summary": final_summary,
            "full_text": text,
            "file_url": file_url
        }
        json_name = f"results/{os.path.splitext(file.filename)[0]}.json"
        bucket.upload_bytes(json.dumps(result_data, ensure_ascii=False).encode("utf-8"),
                            json_name, content_type="application/json")
        json_url = get_signed_url(json_name)

        os.remove(tmp.name)
        return jsonify({
            "subject": subject,
            "summary": final_summary,
            "full_text": text,
            "file_url": file_url,
            "json_url": json_url
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# API: L·∫•y signed URL m·ªõi cho file b·∫•t k·ª≥
@app.route("/get_signed_url", methods=["GET"])
def api_get_signed_url():
    file_name = request.args.get("file_name")
    if not file_name:
        return jsonify({"error": "Thi·∫øu"}), 400
    try:
        return jsonify({"signed_url": get_signed_url(file_name)})
    except Exception as e:
        return jsonify({"error": "L·ªói"}), 500

# API: L·∫•y n·ªôi dung JSON t·ª´ bucket private
@app.route("/get_json_content", methods=["GET"])
def get_json_content():
    file_name = request.args.get("file_name")
    if not file_name:
        return jsonify({"error": "Thi·∫øu"}), 400
    try:
        signed_url = get_signed_url(file_name)
        res = requests.get(signed_url)
        res.raise_for_status()
        return jsonify(res.json())
    except Exception as e:
        return jsonify({"error": "L·ªói"}), 500
        
@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    question = data.get("question")
    context = data.get("context", "")

    if not question:
        return jsonify({"error": "Thi·∫øu c√¢u h·ªèi"}), 400

    # T·∫°o prompt d·ª±a tr√™n transcript
    prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω AI.
    ƒê√¢y l√† n·ªôi dung transcript/t√≥m t·∫Øt:
    {context}

    C√¢u h·ªèi: {question}
    Tr·∫£ l·ªùi b·∫±ng {language_code}, r√µ r√†ng, s√∫c t√≠ch.
    """

    answer = groq_generate(prompt, max_tokens=800)

    return jsonify({"answer": answer})
    
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)



















